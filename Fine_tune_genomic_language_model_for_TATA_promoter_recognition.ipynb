{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install bitsandbytes datasets evaluate peft"
      ],
      "metadata": {
        "id": "AT1-4VckWa58"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-T0nY1mjVUt",
        "outputId": "33548d29-8b09-4a4f-e3b8-f725237179e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/tattabio"
      ],
      "metadata": {
        "id": "qH85_8w-AmFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"tattabio/gLM2_150M\""
      ],
      "metadata": {
        "id": "d-qk4JppQvgG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "5gn1cZzhf_uY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyYycwS4JxFK",
        "outputId": "d0e484cb-3522-45f0-8e49-b91fee2bc1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"InstaDeepAI/nucleotide_transformer_downstream_tasks_revised\", \"promoter_tata\", trust_remote_code=True, revision=\"c8c94743d3d2838b943398ee676247ac2f774122\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "train_valid_split = dataset['train'].train_test_split(test_size=0.15, seed=42)\n",
        "\n",
        "ds = DatasetDict({\n",
        "    'train': train_valid_split['train'],\n",
        "    'validation': train_valid_split['test'],\n",
        "    'test': dataset['test']\n",
        "})\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvTBYiy1hul-",
        "outputId": "0b045423-e967-4ad0-d5c1-f5d2c93235be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sequence', 'name', 'label'],\n",
              "        num_rows: 4302\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sequence', 'name', 'label'],\n",
              "        num_rows: 760\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sequence', 'name', 'label'],\n",
              "        num_rows: 212\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BOd_h6lJf8m",
        "outputId": "f638d6c1-e07a-4c5d-add2-14a13eebb445"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'AATAACTTCACCTAAAAACCAAACGGAAGCATTCACAGACAATTCTTAGTGATCATTGGTTTGAACTAACAGAGCTGAACATTCCTTTAGATGGAGCAGTTTCCAAACCCACTTTCTGTAGAATCTGCAAGTGGATATTTGGACTTCTCTGAGGATTTCGTTGGAAACGGGATAAACTTCCCAGAACTAAACGGAAGCATTCTGAGAAACTTCTTTGTGATGTTTGCATTCAACTCACAGAGTTGAACCTTGCTTTCATAGTTCAGCTTTCAAACACTCTTTTTGTAGAATCTGCAAGTG',\n",
              " 'name': 'chr11:53429000-53429300|0',\n",
              " 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, revision=revision or \"main\")\n",
        "\n",
        "def tokenize(example):\n",
        "  sequence = '<+>' + example['sequence'].lower()\n",
        "\n",
        "  return tokenizer(sequence)"
      ],
      "metadata": {
        "id": "wchOMns8hFNv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds = ds.map(tokenize, remove_columns=['sequence', 'name'])\n",
        "tokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\n",
        "tokenized_ds = tokenized_ds.with_format(\"torch\", device=device)"
      ],
      "metadata": {
        "id": "cFaMnNkYjhB0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyZxhAaSvOu1",
        "outputId": "dea27f9c-f361-4d8d-ee93-454deaf1e5ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 4302\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 760\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 212\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds['train'][0]['input_ids'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzaFu9x_kXdN",
        "outputId": "d5733ae7-fffe-4378-d92a-f551ccd678af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([301])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ds['train'][0]['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW1ZMNsBKcNL",
        "outputId": "aef33c3e-175d-454b-ddda-6f21efc2ec5f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([33, 29, 29, 30, 29, 29, 31, 30, 30, 31, 29, 31, 31, 30, 29, 29, 29, 29,\n",
              "        29, 31, 31, 29, 29, 29, 31, 32, 32, 29, 29, 32, 31, 29, 30, 30, 31, 29,\n",
              "        31, 29, 32, 29, 31, 29, 29, 30, 30, 31, 30, 30, 29, 32, 30, 32, 29, 30,\n",
              "        31, 29, 30, 30, 32, 32, 30, 30, 30, 32, 29, 29, 31, 30, 29, 29, 31, 29,\n",
              "        32, 29, 32, 31, 30, 32, 29, 29, 31, 29, 30, 30, 31, 31, 30, 30, 30, 29,\n",
              "        32, 29, 30, 32, 32, 29, 32, 31, 29, 32, 30, 30, 30, 31, 31, 29, 29, 29,\n",
              "        31, 31, 31, 29, 31, 30, 30, 30, 31, 30, 32, 30, 29, 32, 29, 29, 30, 31,\n",
              "        30, 32, 31, 29, 29, 32, 30, 32, 32, 29, 30, 29, 30, 30, 30, 32, 32, 29,\n",
              "        31, 30, 30, 31, 30, 31, 30, 32, 29, 32, 32, 29, 30, 30, 30, 31, 32, 30,\n",
              "        30, 32, 32, 29, 29, 29, 31, 32, 32, 32, 29, 30, 29, 29, 29, 31, 30, 30,\n",
              "        31, 31, 31, 29, 32, 29, 29, 31, 30, 29, 29, 29, 31, 32, 32, 29, 29, 32,\n",
              "        31, 29, 30, 30, 31, 30, 32, 29, 32, 29, 29, 29, 31, 30, 30, 31, 30, 30,\n",
              "        30, 32, 30, 32, 29, 30, 32, 30, 30, 30, 32, 31, 29, 30, 30, 31, 29, 29,\n",
              "        31, 30, 31, 29, 31, 29, 32, 29, 32, 30, 30, 32, 29, 29, 31, 31, 30, 30,\n",
              "        32, 31, 30, 30, 30, 31, 29, 30, 29, 32, 30, 30, 31, 29, 32, 31, 30, 30,\n",
              "        30, 31, 29, 29, 29, 31, 29, 31, 30, 31, 30, 30, 30, 30, 30, 32, 30, 29,\n",
              "        32, 29, 29, 30, 31, 30, 32, 31, 29, 29, 32, 30, 32], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "EutuzqzMf9h9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_kwargs = {\n",
        "    'pretrained_model_name_or_path': model_name,\n",
        "    'trust_remote_code': True,\n",
        "    'torch_dtype': torch.bfloat16,\n",
        "}"
      ],
      "metadata": {
        "id": "vnx6Jy08Bh8m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -t 0 https://huggingface.co/tattabio/gLM2_150M/resolve/main/modeling_glm2.py\n",
        "! wget -t 0 https://huggingface.co/tattabio/gLM2_150M/resolve/main/configuration_glm2.py\n",
        "! sed -i -e 's/.configuration_glm2/configuration_glm2/g' modeling_glm2.py"
      ],
      "metadata": {
        "id": "kNuYt6MqxHST"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers.modeling_outputs import (\n",
        "    BaseModelOutput,\n",
        "    SequenceClassifierOutput,\n",
        ")\n",
        "\n",
        "from typing import Optional, Union, Tuple\n",
        "from .configuration_glm2 import gLM2Config\n",
        "from .modeling_glm2 import gLM2Model, gLM2PreTrainedModel\n",
        "\n",
        "from transformers import PretrainedConfig\n",
        "from typing import List\n",
        "\n",
        "class gLM2ClassicationConfig(gLM2Config):\n",
        "    def __init__(self, num_classes: int = 2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.auto_map['AutoModelForSequenceClassification'] = \"extension_glm2.gLM2ForSequenceClassification\"\n",
        "\n",
        "class gLM2ForSequenceClassification(gLM2PreTrainedModel):\n",
        "    config_class = gLM2ClassicationConfig\n",
        "\n",
        "    def __init__(self, config: gLM2ClassicationConfig):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.glm2 = gLM2Model(config)\n",
        "\n",
        "        self.score = nn.Linear(config.dim, config.num_classes, bias=False)\n",
        "\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.glm2.tok_embeddings\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.glm2.tok_embeddings = value\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.Tensor,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "        **kwargs,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.glm2(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        token_embeddings = outputs[0]\n",
        "\n",
        "        # use <+> as CLS token\n",
        "        cls_token = token_embeddings[:, 0, :]\n",
        "\n",
        "        logits = self.score(cls_token)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            labels = labels.to(logits.device)\n",
        "\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.config.num_classes), labels.view(-1))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "        )"
      ],
      "metadata": {
        "id": "6r6O4qcVbQaL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gLM2ForSequenceClassification.from_pretrained(**load_kwargs)\n",
        "# TODO: figure out why the classifier weights are not properly initialized at construction\n",
        "nn.init.normal_(model.score.weight, std=0.02)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwDSbMPLLZKB",
        "outputId": "3ed4739c-a5d6-47da-f262-5fd67f545039"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of gLM2ForSequenceClassification were not initialized from the model checkpoint at tattabio/gLM2_150M and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0193, -0.0251,  0.0003,  ..., -0.0018, -0.0002,  0.0215],\n",
              "        [-0.0145, -0.0098,  0.0063,  ...,  0.0053,  0.0131,  0.0057]],\n",
              "       dtype=torch.bfloat16, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of parameters in the model:"
      ],
      "metadata": {
        "id": "IYX2M5ybCFiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.num_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc8AZerwV1RN",
        "outputId": "73c25e57-682d-45bd-d8f1-bbc2a01efdda"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152434560"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bytes in memory:"
      ],
      "metadata": {
        "id": "33w2JA5BCI2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_memory_footprint())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6DCHacGaDpy",
        "outputId": "30d10368-ba69-4d85-a593-b0961272ea28"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "304873080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VFRpjxQ8UKE",
        "outputId": "c15c180b-2610-4aa8-dacc-d33dbd240d2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gLM2ForSequenceClassification(\n",
              "  (glm2): gLM2Model(\n",
              "    (tok_embeddings): Embedding(37, 640)\n",
              "    (encoder): TransformerLayers(\n",
              "      (layers): ModuleList(\n",
              "        (0-29): 30 x TransformerBlock(\n",
              "          (attention): Attention(\n",
              "            (wqkv): Linear(in_features=640, out_features=1920, bias=False)\n",
              "            (wo): Linear(in_features=640, out_features=640, bias=False)\n",
              "            (rotary_emb): RotaryEmbedding()\n",
              "          )\n",
              "          (feed_forward): FeedForward(\n",
              "            (w1): Linear(in_features=640, out_features=1792, bias=False)\n",
              "            (w2): Linear(in_features=1792, out_features=640, bias=False)\n",
              "            (w3): Linear(in_features=640, out_features=1792, bias=False)\n",
              "          )\n",
              "          (attention_norm): RMSNorm()\n",
              "          (ffn_norm): RMSNorm()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (score): Linear(in_features=640, out_features=2, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity check forward pass"
      ],
      "metadata": {
        "id": "8BHu6LA0CBUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model(input_ids=tokenized_ds['train'][:3]['input_ids'], labels=tokenized_ds['train'][:3]['labels'], attention_mask=tokenized_ds['train'][:3]['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcQHRR-Rln91",
        "outputId": "68017f31-0f11-483e-c9c5-d185b23f9d06"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=tensor(0.9414, device='cuda:0', dtype=torch.bfloat16,\n",
              "       grad_fn=<NllLossBackward0>), logits=tensor([[ -7.4688,  -9.6250],\n",
              "        [-12.1875, -15.7500],\n",
              "        [-16.5000, -13.8750]], device='cuda:0', dtype=torch.bfloat16,\n",
              "       grad_fn=<MmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure parameter-efficient fine-tuning"
      ],
      "metadata": {
        "id": "eeLwa1GpBICO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=8,\n",
        "    target_modules=['wqkv'],\n",
        "    modules_to_save=['score'],\n",
        "    lora_dropout=0.5,\n",
        "    bias=\"none\",\n",
        "    inference_mode=False,\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTYTifF3RVWN",
        "outputId": "dec2a37f-19e6-4b60-8945-a29ad4f7efdb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,230,080 || all params: 153,664,640 || trainable%: 0.8005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity check forward pass of LoRA model"
      ],
      "metadata": {
        "id": "sdFzaYBeChNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model(input_ids=tokenized_ds['train'][:3]['input_ids'], labels=tokenized_ds['train'][:3]['labels'], attention_mask=tokenized_ds['train'][:3]['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsoML0PxG6ae",
        "outputId": "9858791a-6401-41d8-fd50-3c37ed5d2b8c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=tensor(0.0615, device='cuda:0', dtype=torch.bfloat16,\n",
              "       grad_fn=<NllLossBackward0>), logits=tensor([[ -7.2500,  -9.5000],\n",
              "        [-12.1875, -15.9375]], device='cuda:0', dtype=torch.bfloat16,\n",
              "       grad_fn=<MmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define evaluation metrics"
      ],
      "metadata": {
        "id": "ySG7HorhClu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return f1.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "Y1ds43BFnt-Q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "c1JkcN56Cn5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"tata_promoter\",\n",
        "    learning_rate=1e-3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=256,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.1,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    remove_unused_columns=False,\n",
        "    label_names=[\"labels\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\",\n",
        "    bf16=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    eval_dataset=tokenized_ds[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "AFWakG9zoXcR",
        "outputId": "7d76887d-e31e-428e-afeb-c41722da39b8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1350/1350 06:01, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.054100</td>\n",
              "      <td>0.487450</td>\n",
              "      <td>0.783479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.713800</td>\n",
              "      <td>0.557080</td>\n",
              "      <td>0.772152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.488600</td>\n",
              "      <td>0.369943</td>\n",
              "      <td>0.839806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>0.280925</td>\n",
              "      <td>0.891892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.226500</td>\n",
              "      <td>0.366166</td>\n",
              "      <td>0.892121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.168800</td>\n",
              "      <td>0.221445</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.181200</td>\n",
              "      <td>0.418254</td>\n",
              "      <td>0.891041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.141200</td>\n",
              "      <td>0.112928</td>\n",
              "      <td>0.961644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.095300</td>\n",
              "      <td>0.159377</td>\n",
              "      <td>0.959049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.078700</td>\n",
              "      <td>0.219075</td>\n",
              "      <td>0.954008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.052200</td>\n",
              "      <td>0.195495</td>\n",
              "      <td>0.956407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.027900</td>\n",
              "      <td>0.203446</td>\n",
              "      <td>0.956175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.026500</td>\n",
              "      <td>0.190027</td>\n",
              "      <td>0.961074</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1350, training_loss=0.342308561846062, metrics={'train_runtime': 361.5204, 'train_samples_per_second': 118.997, 'train_steps_per_second': 3.734, 'total_flos': 1.19369991831552e+16, 'train_loss': 0.342308561846062, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on test set"
      ],
      "metadata": {
        "id": "AFNsJJC5CySZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(tokenized_ds['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "FLTnmuhU37XC",
        "outputId": "b816aac4-d21f-4ee6-a590-2b5d3c122d5c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.053944606333971024,\n",
              " 'eval_f1': 0.9811320754716981,\n",
              " 'eval_runtime': 0.5779,\n",
              " 'eval_samples_per_second': 366.814,\n",
              " 'eval_steps_per_second': 1.73,\n",
              " 'epoch': 10.0}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}